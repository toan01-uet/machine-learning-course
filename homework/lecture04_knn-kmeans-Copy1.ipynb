{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: KNN & K-Means\n",
    "Again, fill the ellipses `...` with code, and don't remove `assert` lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use the Iris dataset again.\n",
    "Just goes to show that `sklearn` makes things way too easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from collections import Counter\n",
    "data = load_iris()\n",
    "X, Y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our data into training and testing set with 90:10 ratio\n",
    "# use a fixed random state for reproducible results\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score normalization.\n",
    "# Remember to scale the training and test set separately to avoid data snooping.\n",
    "# We use the training set's mu and sigma for the test set.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN: $k$-Nearest Neighbors\n",
    "Evaluate the test set with data from the training set.\n",
    "\n",
    "In case of ties, pick the smallest class (i.e. we prefer class 0 to class 1 to class 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Remember, no training is needed for KNN!\n",
    "def evaluateKNN_single(k, x_train, y_train, data):\n",
    "    '''\n",
    "    Evaluate the classification for `data` with k-nearest neighbor\n",
    "    given training set (x_train, y_train).\n",
    "\n",
    "    Note that this function takes in one input instead of the whole\n",
    "    testing set.\n",
    "    \n",
    "    Input:\n",
    "        k      : hyperparameter for KNN\n",
    "        x_train: features of training set\n",
    "        y_train: labels of training set\n",
    "        data   : features of the data point to be evaluated\n",
    "    Output:\n",
    "        Classification of the input data point.\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    distance = list()\n",
    "    for i in range(x_train.shape[0]) :\n",
    "        distance.append((np.linalg.norm([x_train[i]] - data),y_train[i]))\n",
    "    sorted_dis = distance.sort(key = lambda x: x[0])\n",
    "    nearest_labels = np.array(distance)[:k,1]\n",
    "    return int(Counter(nearest_labels).most_common(1)[0][0])\n",
    "\n",
    "evaluateKNN_single(4, x_train, y_train, x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation code for the whole dataset\n",
    "def evaluateKNN(k, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test):\n",
    "    correct = sum(map(lambda x: evaluateKNN_single(k, x_train, y_train, x[0]) == x[1], zip(x_test, y_test)))\n",
    "    print(f'Test accuracy with k={k}: {correct/len(y_test)*100:.4f}% ({correct}/{len(y_test)})')\n",
    "    # return the number of correct evaluations for us to check with the solution\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with k=5: 100.0000% (15/15)\n"
     ]
    }
   ],
   "source": [
    "# and let's see how good is our model with k=5\n",
    "assert evaluateKNN(5) == len(y_test), \"Incorrect accuracy for 5-NN!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with k=1: 93.3333% (14/15)\n"
     ]
    }
   ],
   "source": [
    "# What if we use 1-NN?\n",
    "assert evaluateKNN(1) == len(y_test) - 1, \"Incorrect accuracy for 1-NN!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering\n",
    "Use the first 3 data points as initial cluster centroids (medoids anyone?)\n",
    "\n",
    "Run the recaliberation step 10 times. Yes, it converges that quickly for a NP-hard problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closet_cluster(x_data_point, centroids):\n",
    "    distance = [np.linalg.norm(x_data_point - centroids[i]) for i in range(centroids.shape[0])]\n",
    "    return distance.index(min(distance))\n",
    "def get_cluster_classification(x_data, centroids):\n",
    "    '''\n",
    "    A helper function that you will need later.\n",
    "    Classifies the points to their nearest cluster.\n",
    "    \n",
    "    Input:\n",
    "        x_data   : the data points\n",
    "        centroids: the cluster centroids\n",
    "    Output:\n",
    "        The centroid numbers that each data point belongs to (i.e. is nearest)\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    return np.array([get_closet_cluster(x_data_point, centroids) for x_data_point in x_data ])\n",
    "# print(get_cluster_classification(x_train[0:6],x_train[0:3]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.02028733,  0.90854287, -1.32521428, -1.27540932],\n",
       "       [ 0.99363929,  0.01896468,  0.90355632,  0.92076921],\n",
       "       [-0.22539812, -1.02749927,  0.23322382,  0.15491878]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def kmeans(x_train, k, step):\n",
    "    '''\n",
    "    An implementation of K-means clustering.\n",
    "    \n",
    "    Input:\n",
    "        k      : number of clusters\n",
    "        x_train: training dataset\n",
    "        step   : number of recaliberation steps\n",
    "    Output:\n",
    "        The centroids of the clusters (a k x d matrix)\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    \n",
    "    centroids = x_train[:3]\n",
    "    for i in range(step):\n",
    "        clusters = get_cluster_classification(x_train, centroids)\n",
    "        new_centroids = np.array([np.mean(x_train[clusters == j], axis = 0) for j in range(k)])\n",
    "        if np.allclose(new_centroids, centroids): break\n",
    "        centroids = new_centroids\n",
    "    return centroids\n",
    "\n",
    "kmeans(x_train,3,10)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know that there are three classes\n",
    "centroids = kmeans(x_train, k=3, step=10)\n",
    "assert np.allclose(centroids, np.array([\n",
    "    [-1.02028733,  0.90854287, -1.32521428, -1.27540932],\n",
    "    [ 0.99363929,  0.01896468,  0.90355632,  0.92076921],\n",
    "    [-0.22539812, -1.02749927,  0.23322382,  0.15491878]\n",
    "])), \"Incorrect centroids for K-means!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means++\n",
    "Use the 4th data point as the intial centroid each step ([chosen with randomness](https://xkcd.com/221/)):\n",
    "- The first initial centroid should be the 4th data point.\n",
    "- The next initial centroids should be the 4th furthest data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpp_centroids(x_train,k):\n",
    "    centroids = np.array([x_train[3]])\n",
    "    for i in range(k-1) :\n",
    "        distance = [(np.linalg.norm([j] - centroids[-1]),j) for j in x_train]\n",
    "        sorted_dis = sorted(distance,key = lambda x: x[0])\n",
    "        next_centroid = [sorted_dis[-4][1]]\n",
    "        centroids = np.concatenate((centroids,next_centroid), axis=0)\n",
    "    return centroids\n",
    "\n",
    "# print(kpp_centroids(x_train,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([[1, 2], [3, 4]])\n",
    "# b = np.array([[5, 6]])\n",
    "# x = np.concatenate((a, b), axis=0)\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeanspp(x_train, k, step):\n",
    "    '''\n",
    "    An implementation of K-means++ clustering.\n",
    "    \n",
    "    Input:\n",
    "        k      : number of clusters\n",
    "        x_train: training dataset\n",
    "        step   : number of recaliberation steps\n",
    "    Output:\n",
    "        The centroids of the clusters (a k x d matrix)\n",
    "    '''\n",
    "    # initialize the centroids according to the above criteria\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    \n",
    "    \n",
    "    centroids = kpp_centroids(x_train,k)\n",
    "    for i in range(step):\n",
    "        clusters = get_cluster_classification(x_train, centroids)\n",
    "        new_centroids = np.array([np.mean(x_train[clusters == j], axis = 0) for j in range(k)])\n",
    "        if np.allclose(new_centroids, centroids): break\n",
    "        centroids = new_centroids\n",
    "    return centroids\n",
    "    \n",
    "    # the rest should be identical to kmeans()\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check if you did it correctly.\n",
    "centroidspp = kmeanspp(x_train, k=3, step=10)\n",
    "assert np.allclose(centroidspp, np.array([\n",
    "    [-0.0118057 , -0.87997489,  0.36942197,  0.30573876],\n",
    "    [ 1.15200055,  0.18878042,  0.98903982,  1.01136932],\n",
    "    [-1.03358934,  0.84835232, -1.32732076, -1.27380566]\n",
    "])), \"Incorrect centroids for K-means++!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Classification using clustering\n",
    "We can treat each cluster to be of a different class, and the class with most points in each cluster is the classification for that cluster. Think voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the associated classification for each cluster\n",
    "def get_cluster_label(centroids, x_train, y_train):\n",
    "    '''\n",
    "    Get the classification for each cluster using training set.\n",
    "    \n",
    "    Input:\n",
    "        centroids: the centroids of the clusters\n",
    "        x_train  : features of training set\n",
    "        y_train  : labels of training set\n",
    "    Output:\n",
    "        The classifications for the clusters.\n",
    "    '''\n",
    "    # remember to return a numpy array instead of a Python list!\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    clusters = get_cluster_classification(x_train,centroids)\n",
    "    ## voting\n",
    "    return np.array([Counter(y_train[clusters == i]).most_common(1)[0][0] for i in range(len(centroids))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(get_cluster_label(centroids, x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_cluster_label(centroids, x_train, y_train)\n",
    "labelspp = get_cluster_label(centroidspp, x_train, y_train)\n",
    "# each cluster nicely belongs to a different class\n",
    "assert (labels == [0, 2, 1]).all(), \"Incorrect K-means cluster label(s)!\"\n",
    "assert (labelspp == [1, 2, 0]).all(), \"Incorrect K-means++ cluster label(s)!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kmeans_classification(centroids, labels, x_data):\n",
    "    '''\n",
    "    Get the classification for each data point using centroid labels.\n",
    "    \n",
    "    Input:\n",
    "        centroids: the centroids of the clusters\n",
    "        labels   : the labels for the clusters\n",
    "        x_data   : the data to be classified\n",
    "    Output:\n",
    "        The classifications for the data.\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    cluster = get_cluster_classification(x_data,centroids)\n",
    "    return np.array([labels[i] for i in cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(np.array([\n",
    "    [-0.0118057 , -0.87997489,  0.36942197,  0.30573876],\n",
    "    [ 1.15200055,  0.18878042,  0.98903982,  1.01136932],\n",
    "    [-1.03358934,  0.84835232, -1.32732076, -1.27380566]\n",
    "]),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 2 0 0 1 2 0 0 0 1 2 2 0 0 1 2 2 2 2 1 2\n",
      " 1 0 2 1 0 0 0 1 2 0 0 0 1 0 1 2 0 1 1 0 2 1 1 1 2 1 0 1 2 0 0 1 2 0 2 0 0\n",
      " 2 1 2 1 1 2 1 0 0 1 2 0 0 0 1 2 0 2 2 0 1 2 2 2 2 0 2 1 2 1 1 2 1 2 1 0 1\n",
      " 2 2 0 1 2 2 0 2 0 2 2 2 1 2 1 2 1 2 0 1 1 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_kmeans_classification(centroids, labels, x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the classifications\n",
    "y_train_pred = evaluate_kmeans_classification(centroids, labels, x_train)\n",
    "y_test_pred = evaluate_kmeans_classification(centroids, labels, x_test)\n",
    "y_train_pred_pp = evaluate_kmeans_classification(centroidspp, labelspp, x_train)\n",
    "y_test_pred_pp = evaluate_kmeans_classification(centroidspp, labelspp, x_test)\n",
    "\n",
    "# and check for correctness\n",
    "assert (y_train_pred == [2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 2, 1, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 2, 0, 2, 0, 0, 2, 1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 2, 1, 2, 1, 1, 2, 1, 2, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 2, 1, 2, 0, 1, 1, 0, 1, 2]).all()\n",
    "assert (y_test_pred == [1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0]).all()\n",
    "assert (y_train_pred_pp == [2, 2, 1, 1, 2, 0, 1, 0, 2, 2, 2, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0, 2, 1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 1, 2, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2]).all()\n",
    "assert (y_test_pred_pp == [1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] For K-means:\n",
      "Training accuracy: 82.9630% (112/135)\n",
      "Training accuracy: 93.3333% (14/15)\n",
      "[+] For K-means++:\n",
      "Training accuracy: 80.0000% (108/135)\n",
      "Training accuracy: 93.3333% (14/15)\n"
     ]
    }
   ],
   "source": [
    "# evaluate prediction accuracy\n",
    "print('[+] For K-means:')\n",
    "train_score = np.sum(y_train_pred == y_train)\n",
    "print(f'Training accuracy: {train_score / len(y_train) * 100:.4f}% ({train_score}/{len(y_train)})')\n",
    "train_score = np.sum(y_test_pred == y_test)\n",
    "print(f'Training accuracy: {train_score / len(y_test) * 100:.4f}% ({train_score}/{len(y_test)})')\n",
    "print('[+] For K-means++:')\n",
    "train_score = np.sum(y_train_pred_pp == y_train)\n",
    "print(f'Training accuracy: {train_score / len(y_train) * 100:.4f}% ({train_score}/{len(y_train)})')\n",
    "train_score = np.sum(y_test_pred_pp == y_test)\n",
    "print(f'Training accuracy: {train_score / len(y_test) * 100:.4f}% ({train_score}/{len(y_test)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# and plot out confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "fig = plt.subplot(2, 2, 1)\n",
    "sn.heatmap(confusion_matrix(y_train, y_train_pred), annot=True, cbar=False, square=True, linewidths=0.5)\n",
    "fig.set_title('K-means, train set')\n",
    "\n",
    "fig = plt.subplot(2, 2, 2)\n",
    "sn.heatmap(confusion_matrix(y_test, y_test_pred), annot=True, cbar=False, square=True, linewidths=0.5)\n",
    "fig.set_title('K-means, test set')\n",
    "\n",
    "fig = plt.subplot(2, 2, 3)\n",
    "sn.heatmap(confusion_matrix(y_train, y_train_pred_pp), annot=True, cbar=False, square=True, linewidths=0.5)\n",
    "fig.set_title('K-means++, train set')\n",
    "\n",
    "fig = plt.subplot(2, 2, 4)\n",
    "sn.heatmap(confusion_matrix(y_test, y_test_pred_pp), annot=True, cbar=False, square=True, linewidths=0.5)\n",
    "fig.set_title('K-means++, test set');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
